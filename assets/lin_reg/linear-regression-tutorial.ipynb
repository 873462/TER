{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Tutorial\n",
    "\n",
    "Author: Andrew Andrade ([andrew@andrewandrade.ca](mailto:andrew@andrewandrade.ca))\n",
    "\n",
    "This is part one of a series of tutorials related to regression used in data science.\n",
    "\n",
    "In this tutorial we will fit a simple line using Least Squares Linear Regression (LSLR), examine residuals, plot distributions, compare vertical vs horizontal vs perpendicular residuals, and end with total least squares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "\n",
    "# Try to import sklearn, else install\n",
    "try:\n",
    "    from sklearn import linear_model\n",
    "except ModuleNotFoundError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install scikit-learn\n",
    "    from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["Read the data and display it."]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "anscombe_i = pd.read_csv('anscombe_i.csv')\n",
    "anscombe_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Linear Regression using sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_i = linear_model.LinearRegression()\n",
    "\n",
    "X = anscombe_i.x.values.reshape(-1, 1)\n",
    "y = anscombe_i.y.values.reshape(-1, 1)\n",
    "\n",
    "regr_i.fit(X, y)\n",
    "\n",
    "print('Coefficient (m):', regr_i.coef_[0][0])\n",
    "print('Intercept (b):', regr_i.intercept_[0])\n",
    "print('Residual Sum of Squares:', np.mean((regr_i.predict(X) - y) ** 2))\n",
    "print('Variance Score:', regr_i.score(X, y))\n",
    "\n",
    "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n",
    "plt.plot(X, regr_i.predict(X), color='green', linewidth=3)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Plot Residuals (Vertical)"]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import polyfit\n",
    "\n",
    "k, d = polyfit(anscombe_i.x, anscombe_i.y, 1)\n",
    "yfit = k * anscombe_i.x + d\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n",
    "plt.plot(anscombe_i.x, yfit, color='green')\n",
    "\n",
    "for i in range(len(anscombe_i)):\n",
    "    plt.plot([anscombe_i.x[i], anscombe_i.x[i]], [anscombe_i.y[i], yfit[i]], 'k')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Residual Distribution"]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = anscombe_i.y - yfit\n",
    "mean_r = np.mean(residual)\n",
    "std_r = np.std(residual)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(anscombe_i.x, residual)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Residual')\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.hist(residual, bins=10, density=True, alpha=0.75)\n",
    "\n",
    "from scipy.stats import norm\n",
    "xvals = np.linspace(min(residual), max(residual), 100)\n",
    "plt.plot(xvals, norm.pdf(xvals, mean_r, std_r), 'k--')\n",
    "plt.xlabel('Residual Error')\n",
    "plt.title('Residual Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Statsmodels OLS"]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(anscombe_i.x)\n",
    "model = sm.OLS(anscombe_i.y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Statsmodels Regression Line"]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n",
    "\n",
    "xp = np.linspace(anscombe_i.x.min(), anscombe_i.x.max(), 100)\n",
    "Xp = sm.add_constant(xp)\n",
    "plt.plot(xp, model.predict(Xp), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Seaborn Regression + Marginals"]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style='darkgrid', color_codes=True)\n",
    "\n",
    "sns.jointplot(data=anscombe_i, x='x', y='y', kind='reg', height=6, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Horizontal Residual Regression"]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k2, d2 = polyfit(anscombe_i.y, anscombe_i.x, 1)\n",
    "xfit = k2 * anscombe_i.y + d2\n",
    "\n",
    "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n",
    "plt.plot(xfit, anscombe_i.y, 'blue')\n",
    "\n",
    "for i in range(len(anscombe_i)):\n",
    "    plt.plot([anscombe_i.x[i], xfit[i]], [anscombe_i.y[i], anscombe_i.y[i]], 'k')\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Total Least Squares (Orthogonal Regression)"]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.odr import Model, Data, ODR\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def fit_function(p, x):\n",
    "    return p[0] * x + p[1]\n",
    "\n",
    "def orthoregress(x, y):\n",
    "    lr = linregress(x, y)\n",
    "    model = Model(fit_function)\n",
    "    data = Data(x, y)\n",
    "    od = ODR(data, model, beta0=lr[0:2])\n",
    "    out = od.run()\n",
    "    return out.beta\n",
    "\n",
    "m, b = orthoregress(anscombe_i.x.values, anscombe_i.y.values)\n",
    "\n",
    "y_ortho = m * anscombe_i.x + b\n",
    "\n",
    "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n",
    "plt.plot(anscombe_i.x, y_ortho, 'r')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## Compare All Three Regression Lines"]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n",
    "plt.plot(anscombe_i.x, yfit, 'g', label='Vertical Residuals')\n",
    "plt.plot(xfit, anscombe_i.y, 'b', label='Horizontal Residuals')\n",
    "plt.plot(anscombe_i.x, y_ortho, 'r', label='Total Least Squares')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
